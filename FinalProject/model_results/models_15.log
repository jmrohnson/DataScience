INFO:root:All Data Loaded
INFO:root:============================================================
INFO:root:Grid Search SVM on ALL Text with strong features
INFO:root:All Data Loaded
INFO:root:============================================================
INFO:root:Grid Search SVM on ALL Text with strong features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.71      0.78      7590
       True       0.75      0.88      0.81      7590

avg / total       0.81      0.80      0.80     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.33      0.73      0.45      1706
       True       0.92      0.66      0.77      7582

avg / total       0.81      0.67      0.71      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL Text with weak features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.88      0.73      0.80      7590
       True       0.77      0.90      0.83      7590

avg / total       0.82      0.81      0.81     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.33      0.74      0.45      1706
       True       0.92      0.66      0.77      7582

avg / total       0.81      0.67      0.71      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL Text with n1 features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.80      0.83      7590
       True       0.81      0.87      0.84      7590

avg / total       0.83      0.83      0.83     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.78      0.43      1706
       True       0.92      0.58      0.71      7582

avg / total       0.81      0.62      0.66      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL Text with n2 features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.94      0.87      0.90      7590
       True       0.88      0.95      0.91      7590

avg / total       0.91      0.91      0.91     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.80      0.44      1706
       True       0.93      0.59      0.72      7582

avg / total       0.81      0.63      0.67      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL Text with all features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.94      0.87      0.91      7590
       True       0.88      0.95      0.91      7590

avg / total       0.91      0.91      0.91     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.80      0.44      1706
       True       0.93      0.59      0.72      7582

avg / total       0.81      0.63      0.67      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL DATA with strong features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.54      0.66      7590
       True       0.66      0.91      0.77      7590

avg / total       0.76      0.73      0.72     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.32      0.62      0.42      1706
       True       0.89      0.70      0.79      7582

avg / total       0.79      0.69      0.72      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.83      0.65      0.73      7590
       True       0.71      0.87      0.78      7590

avg / total       0.77      0.76      0.76     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.32      0.67      0.43      1706
       True       0.90      0.68      0.78      7582

avg / total       0.79      0.68      0.71      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.72      0.78      7590
       True       0.76      0.88      0.81      7590

avg / total       0.81      0.80      0.80     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.31      0.74      0.44      1706
       True       0.91      0.63      0.74      7582

avg / total       0.80      0.65      0.69      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.71      0.78      7590
       True       0.75      0.88      0.81      7590

avg / total       0.81      0.80      0.80     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.33      0.73      0.45      1706
       True       0.92      0.66      0.77      7582

avg / total       0.81      0.67      0.71      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.90      0.77      0.83      7590
       True       0.80      0.91      0.85      7590

avg / total       0.85      0.84      0.84     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.75      0.43      1706
       True       0.92      0.61      0.73      7582

avg / total       0.80      0.63      0.67      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.88      0.75      0.81      7590
       True       0.78      0.90      0.84      7590

avg / total       0.83      0.82      0.82     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.32      0.76      0.44      1706
       True       0.92      0.63      0.75      7582

avg / total       0.81      0.65      0.69      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.91      0.80      0.85      7590
       True       0.82      0.92      0.87      7590

avg / total       0.86      0.86      0.86     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.76      0.42      1706
       True       0.91      0.58      0.71      7582

avg / total       0.80      0.62      0.66      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.90      0.78      0.83      7590
       True       0.80      0.91      0.85      7590

avg / total       0.85      0.84      0.84     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.76      0.43      1706
       True       0.92      0.60      0.73      7582

avg / total       0.80      0.63      0.67      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.91      0.81      0.86      7590
       True       0.83      0.92      0.87      7590

avg / total       0.87      0.86      0.86     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.75      0.42      1706
       True       0.91      0.58      0.71      7582

avg / total       0.80      0.61      0.66      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.90      0.79      0.84      7590
       True       0.82      0.91      0.86      7590

avg / total       0.86      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.76      0.42      1706
       True       0.92      0.58      0.71      7582

avg / total       0.80      0.62      0.66      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.91      0.81      0.86      7590
       True       0.83      0.92      0.87      7590

avg / total       0.87      0.86      0.86     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.75      0.41      1706
       True       0.91      0.58      0.71      7582

avg / total       0.80      0.61      0.65      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.91      0.80      0.85      7590
       True       0.82      0.92      0.87      7590

avg / total       0.87      0.86      0.86     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.76      0.42      1706
       True       0.91      0.58      0.71      7582

avg / total       0.80      0.61      0.66      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL DATA with weak features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.54      0.66      7590
       True       0.66      0.91      0.77      7590

avg / total       0.76      0.73      0.72     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.32      0.62      0.42      1706
       True       0.89      0.70      0.79      7582

avg / total       0.79      0.69      0.72      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.84      0.66      0.74      7590
       True       0.72      0.87      0.79      7590

avg / total       0.78      0.77      0.76     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.32      0.68      0.44      1706
       True       0.90      0.68      0.78      7582

avg / total       0.80      0.68      0.71      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.72      0.79      7590
       True       0.76      0.89      0.82      7590

avg / total       0.81      0.80      0.80     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.31      0.74      0.44      1706
       True       0.92      0.63      0.74      7582

avg / total       0.80      0.65      0.69      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.88      0.73      0.80      7590
       True       0.77      0.90      0.83      7590

avg / total       0.82      0.81      0.81     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.33      0.74      0.45      1706
       True       0.92      0.66      0.77      7582

avg / total       0.81      0.67      0.71      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.91      0.81      0.86      7590
       True       0.83      0.92      0.87      7590

avg / total       0.87      0.87      0.87     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.75      0.43      1706
       True       0.91      0.61      0.73      7582

avg / total       0.80      0.63      0.68      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.91      0.78      0.84      7590
       True       0.81      0.92      0.86      7590

avg / total       0.86      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.32      0.76      0.45      1706
       True       0.92      0.64      0.75      7582

avg / total       0.81      0.66      0.70      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.93      0.84      0.89      7590
       True       0.86      0.94      0.90      7590

avg / total       0.90      0.89      0.89     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.77      0.41      1706
       True       0.92      0.56      0.70      7582

avg / total       0.80      0.60      0.64      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.92      0.82      0.87      7590
       True       0.83      0.93      0.88      7590

avg / total       0.88      0.87      0.87     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.76      0.43      1706
       True       0.92      0.60      0.72      7582

avg / total       0.80      0.63      0.67      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.94      0.85      0.89      7590
       True       0.87      0.94      0.90      7590

avg / total       0.90      0.90      0.90     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.77      0.41      1706
       True       0.91      0.55      0.69      7582

avg / total       0.80      0.59      0.64      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.93      0.84      0.88      7590
       True       0.85      0.94      0.89      7590

avg / total       0.89      0.89      0.89     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.77      0.42      1706
       True       0.92      0.57      0.70      7582

avg / total       0.80      0.60      0.65      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.94      0.86      0.90      7590
       True       0.87      0.94      0.90      7590

avg / total       0.90      0.90      0.90     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.77      0.41      1706
       True       0.91      0.55      0.68      7582

avg / total       0.80      0.59      0.63      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.94      0.85      0.89      7590
       True       0.86      0.94      0.90      7590

avg / total       0.90      0.89      0.89     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.77      0.41      1706
       True       0.92      0.55      0.69      7582

avg / total       0.80      0.59      0.64      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL DATA with n1 features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.79      0.68      0.73      7590
       True       0.72      0.82      0.77      7590

avg / total       0.76      0.75      0.75     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.73      0.42      1706
       True       0.91      0.61      0.73      7582

avg / total       0.80      0.63      0.67      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.83      0.74      0.78      7590
       True       0.77      0.84      0.80      7590

avg / total       0.80      0.79      0.79     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.76      0.43      1706
       True       0.92      0.60      0.73      7582

avg / total       0.80      0.63      0.67      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.85      0.78      0.81      7590
       True       0.80      0.86      0.83      7590

avg / total       0.82      0.82      0.82     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.78      0.42      1706
       True       0.92      0.57      0.71      7582

avg / total       0.80      0.61      0.66      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.80      0.83      7590
       True       0.81      0.87      0.84      7590

avg / total       0.83      0.83      0.83     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.78      0.43      1706
       True       0.92      0.58      0.71      7582

avg / total       0.81      0.62      0.66      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.87      0.83      0.85      7590
       True       0.83      0.87      0.85      7590

avg / total       0.85      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.78      0.42      1706
       True       0.92      0.56      0.70      7582

avg / total       0.80      0.60      0.65      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.87      0.82      0.84      7590
       True       0.83      0.87      0.85      7590

avg / total       0.85      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.78      0.42      1706
       True       0.92      0.56      0.70      7582

avg / total       0.80      0.60      0.65      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.87      0.83      0.85      7590
       True       0.84      0.87      0.85      7590

avg / total       0.85      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.78      0.42      1706
       True       0.92      0.56      0.70      7582

avg / total       0.80      0.60      0.64      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.87      0.83      0.85      7590
       True       0.84      0.87      0.85      7590

avg / total       0.85      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.78      0.42      1706
       True       0.92      0.56      0.69      7582

avg / total       0.80      0.60      0.64      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.83      0.85      7590
       True       0.84      0.87      0.85      7590

avg / total       0.85      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.78      0.42      1706
       True       0.92      0.56      0.69      7582

avg / total       0.80      0.60      0.64      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.87      0.83      0.85      7590
       True       0.84      0.87      0.85      7590

avg / total       0.85      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.78      0.42      1706
       True       0.92      0.56      0.69      7582

avg / total       0.80      0.60      0.64      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.83      0.85      7590
       True       0.84      0.87      0.85      7590

avg / total       0.85      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.78      0.42      1706
       True       0.92      0.56      0.69      7582

avg / total       0.80      0.60      0.64      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.87      0.83      0.85      7590
       True       0.84      0.87      0.85      7590

avg / total       0.85      0.85      0.85     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.78      0.42      1706
       True       0.92      0.56      0.69      7582

avg / total       0.80      0.60      0.64      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL DATA with n2 features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.82      0.65      0.72      7590
       True       0.71      0.85      0.77      7590

avg / total       0.76      0.75      0.75     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.72      0.43      1706
       True       0.91      0.63      0.74      7582

avg / total       0.80      0.65      0.69      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.76      0.81      7590
       True       0.78      0.88      0.83      7590

avg / total       0.82      0.82      0.82     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.31      0.77      0.44      1706
       True       0.92      0.61      0.74      7582

avg / total       0.81      0.64      0.68      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.87      0.78      0.83      7590
       True       0.80      0.88      0.84      7590

avg / total       0.84      0.83      0.83     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.80      0.42      1706
       True       0.92      0.56      0.70      7582

avg / total       0.81      0.60      0.65      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.94      0.87      0.90      7590
       True       0.88      0.95      0.91      7590

avg / total       0.91      0.91      0.91     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.80      0.44      1706
       True       0.93      0.59      0.72      7582

avg / total       0.81      0.63      0.67      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.99      0.97      0.98      7590
       True       0.97      0.99      0.98      7590

avg / total       0.98      0.98      0.98     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.83      0.41      1706
       True       0.93      0.51      0.66      7582

avg / total       0.81      0.57      0.61      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.99      0.97      0.98      7590
       True       0.97      0.99      0.98      7590

avg / total       0.98      0.98      0.98     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.82      0.43      1706
       True       0.93      0.56      0.70      7582

avg / total       0.81      0.61      0.65      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.27      0.83      0.41      1706
       True       0.93      0.49      0.64      7582

avg / total       0.81      0.55      0.60      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      0.99      1.00      7590
       True       0.99      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.82      0.42      1706
       True       0.93      0.54      0.68      7582

avg / total       0.81      0.59      0.63      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.27      0.82      0.41      1706
       True       0.93      0.51      0.65      7582

avg / total       0.81      0.56      0.61      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.82      0.42      1706
       True       0.93      0.53      0.67      7582

avg / total       0.81      0.58      0.63      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.27      0.81      0.41      1706
       True       0.92      0.51      0.66      7582

avg / total       0.80      0.57      0.61      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.82      0.42      1706
       True       0.93      0.52      0.67      7582

avg / total       0.81      0.58      0.62      9288

INFO:root:============================================================
INFO:root:Grid Search SVM on ALL DATA with all features
INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.82      0.65      0.72      7590
       True       0.71      0.86      0.77      7590

avg / total       0.76      0.75      0.75     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.72      0.43      1706
       True       0.91      0.63      0.74      7582

avg / total       0.80      0.65      0.69      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =0.100000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.86      0.76      0.81      7590
       True       0.78      0.88      0.83      7590

avg / total       0.82      0.82      0.82     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.31      0.77      0.44      1706
       True       0.92      0.61      0.74      7582

avg / total       0.81      0.64      0.68      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.87      0.78      0.82      7590
       True       0.80      0.88      0.84      7590

avg / total       0.84      0.83      0.83     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.80      0.43      1706
       True       0.93      0.56      0.70      7582

avg / total       0.81      0.60      0.65      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.94      0.87      0.91      7590
       True       0.88      0.95      0.91      7590

avg / total       0.91      0.91      0.91     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.30      0.80      0.44      1706
       True       0.93      0.59      0.72      7582

avg / total       0.81      0.63      0.67      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.99      0.96      0.97      7590
       True       0.96      0.99      0.97      7590

avg / total       0.97      0.97      0.97     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.81      0.41      1706
       True       0.92      0.52      0.67      7582

avg / total       0.80      0.57      0.62      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       0.99      0.97      0.98      7590
       True       0.97      0.99      0.98      7590

avg / total       0.98      0.98      0.98     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.82      0.43      1706
       True       0.93      0.56      0.70      7582

avg / total       0.81      0.60      0.65      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.27      0.81      0.41      1706
       True       0.92      0.52      0.66      7582

avg / total       0.80      0.57      0.62      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =100.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      0.99      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.29      0.83      0.43      1706
       True       0.93      0.53      0.68      7582

avg / total       0.81      0.59      0.63      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.27      0.81      0.41      1706
       True       0.92      0.51      0.66      7582

avg / total       0.80      0.57      0.61      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =1000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.83      0.42      1706
       True       0.93      0.53      0.67      7582

avg / total       0.81      0.58      0.63      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l1 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.80      0.41      1706
       True       0.92      0.53      0.67      7582

avg / total       0.80      0.58      0.62      9288

INFO:root:-------- LogisticRegression via linear_model.LogisticRegression C =10000.000000, Penalty = l2 ------------
INFO:root:--------PERFORMANCE ON TRAINING DATA------------
INFO:root:             precision    recall  f1-score   support

      False       1.00      1.00      1.00      7590
       True       1.00      1.00      1.00      7590

avg / total       1.00      1.00      1.00     15180

INFO:root:----------PERFORMANCE ON TEST DATA--------------
INFO:root:             precision    recall  f1-score   support

      False       0.28      0.83      0.42      1706
       True       0.93      0.52      0.67      7582

avg / total       0.81      0.58      0.62      9288

